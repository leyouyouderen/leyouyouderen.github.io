---
title: "Active Learning with Maximum Margin Sparse Gaussian Processes"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-2
excerpt: 'We present a maximum-margin sparse Gaussian Process (MM-SGP) for active learning
(AL) of classification models for multi-class
problems. The proposed model makes novel
extensions to a GP by integrating maximummargin constraints into its learning process,
aiming to further improve its predictive power
while keeping its inherent capability for uncertainty quantification. The MM constraints ensure small “effective size” of the model, which
allows MM-SGP to provide good predictive
performance by using limited “active” data
samples, a critical property for AL. Furthermore, as a Gaussian process model, MM-SGP
will output both the predicted class distribution and the predictive variance, both of which
are essential for defining a sampling function
effective to improve the decision boundaries
of a large number of classes simultaneously.
Finally, the sparse nature of MM-SGP ensures that it can be efficiently trained by solving a low-rank convex dual problem. Experiment results on both synthetic and real-world
datasets show the effectiveness and efficiency
of the proposed AL model.'
date: 2021-10-1
venue: ' International Conference on Artificial Intelligence and Statistics (AISTATS)  '
paperurl: 'http://proceedings.mlr.press/v130/shi21a/shi21a.pdf'
citation: 'Shi, Weishi, and Qi Yu. "Active Learning with Maximum Margin Sparse Gaussian Processes." International Conference on Artificial Intelligence and Statistics. PMLR, 2021.'
---

[Download](http://proceedings.mlr.press/v130/shi21a/shi21a.pdf)

